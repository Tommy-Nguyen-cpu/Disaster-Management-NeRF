# Data Science Foundations - NeRF-- In Disaster Management
## Introduction
The growing occurrence of natural disasters in Africa (Libya flooding and Morocco earthquake) underscores the critical role of disaster management in addressing and mitigating the aftermath of these calamities. Specifically, efficient response teams and disaster management analysts are vital in ensuring the safe rescue and support of those affected by natural disasters. Their roles are instrumental in delivering necessary aid and assistance to those in need. An essential element in disaster management planning involves assessing the landscape and determining the most efficient routes to rescue and safeguard lives. However, this task becomes challenging during disasters, as videos and images often lack the interactivity necessary for response teams to locate and assist individuals in distress. In turn, 3D models serve as a viable alternative to videos and images, offering response teams the ability to identify optimal routes for rescue operations. Moreover, disaster management analysts can leverage these 3D models to conduct real-time and post-disaster analyses. This includes assessing the extent of damage, identifying the causes of the disaster, exploring preventive measures, and devising more efficient strategies to aid a larger population in need. As of the current writing, several algorithms endeavor to generate 3D models from image inputs. Yet, these methods often demand costly tools, additional inputs that might be inaccessible during disasters, or extensive memory usage for running the application. In contrast, NeRF Minus Minus (NeRF--) presents an attractive alternative. NeRF-- removes the necessity for expensive tools, relies solely on images as input, and optimizes memory usage. Consequently, NeRF-- emerges as an optimal solution for creating realistic forward-facing 3D models pertinent to disaster management. We aim to demonstrate NeRF--'s potential in disaster management by showcasing its efficiency and minimal data preparation requirements. <br />
Our experiment revealed NeRF--'s strengths and limitations in disaster management applications. While it effectively handled forward-facing scenes without COLMAP, its computational complexity and space requirements posed challenges. The model took approximately 2 hours to complete 10,000 epochs on 6 images, even with image resizing to 400x400. This resizing, however, introduced more noise (blurriness) and lowered the PSNR score.
## Selection of Data
NeRF-- stands out from other algorithms due to its unique approach: it undergoes training each time a new scene requires rendering. This implies that the training of a NeRF-- model and the generation of a 3D representation for a scene during testing are integrated into a single process. Consequently, a massive dataset isn't essential; instead, images of the scene serve as the training data for NeRF--. To achieve satisfactory outcomes using the NeRF-- model for a particular scene, two key criteria must be met: the images should adhere to the capture method specified in the LLFF paper, and the scene should have a forward-facing orientation. <br />
![LLFF instructions for capturing images.](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/Images/LLFFDinosaur.png) <br />
The red squares delineate the designated image capture zones, requiring consistent formatting and uniformity across all images. <br />
Given these requirements, here is the first row of images (first 3 images taken): <br />
![First image captured](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/custom_upload/20231121_123031.jpg) <br />
![Second image captured](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/custom_upload/20231121_123033.jpg) <br />
![Third image captured](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/custom_upload/20231121_123035.jpg) <br />
NeRF--, like many NeRF variants, learns on a per-scene basis, eliminating the need for extensive feature engineering. The model directly learns from the images provided during testing. In lieu of feature engineering, we resorted to resizing the images to accommodate memory constraints. However, as previously mentioned, this resizing introduced increased noise (blurriness) and a lower PSNR score.
## Methods
### Tools Used
- NumPy, Matplotlib, and PyTorch
- VS Code
- NeRFMM utility library (for encoding position, volume sampling, etc).
<!-- --> 
<br />
The model utilized in this scenario was a fully connected neural network, commonly referred to as a Multilayer Perceptron (MLP). Within the MLP architecture, there were 8 fully connected layers employing the Rectified Linear Unit (ReLU) as the activation function. Additionally, the model consisted of 2 fully connected layers dedicated to density and feature information (without any activation function), along with 2 RGB layers. <br />
Originally, the NeRF-- model incorporated 4 fully connected layers utilizing ReLU activations. However, in this instance, the layer count was augmented to 8. This adjustment aimed to explore the full potential of NeRF--, despite the potential increase in computational costs. While further modifications, such as altering dimensions, could be contemplated, implementing such changes might render NeRF-- computationally unfeasible for execution on the current hardware setup. <br />
The hyperparameters in the NeRF-- model have been retained at their default settings, and the optimization metric employed for NeRF-- is PSNR (Peak Signal-to-Noise Ratio).

## Results
An experiment was conducted to test two sets of images capturing the Wentworth quad: one set captured from the second floor of the CEIS building, and the other from the third floor. <br />
Given the 6 images captured from the second floor of CEIS, here is one of the images rendered by NeRF--: <br />
![Final Rendered Result](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/Images/Quad2ndFLResult.png) <br />
The model ran for 10,000 epochs, which theoretically should have been sufficient for the scene learning process. However, the final rendered image and resulting model failed to render a high-detail, low-noise model. Various potential reasons for this outcome will be discussed in the "Discussion" section. <br />
The chart below shows the PSNR score of the model after 10,000 iterations: <br />
![First image captured](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/Images/PSNR2ndFL.png) <br />
A good PSNR score for images typically falls within the 30-40 range. However, in our instance, our NeRF-- model plateaued at approximately 22. Despite the lower PSNR score, the rendered image displayed general colors and shapes of objects within the scene, suggesting that the model learned the overall shape and color but possibly oversmoothed some scene details. Additionally, within 10,000 epochs, NeRF-- might not have fully learned the specific colors for certain pixels, resulting in visible artifacts in the final rendered model. <br />
Training the model for additional epochs could potentially improve these aspects, but this would demand more time. The training time for just 10,000 epochs alone amounted to roughly 2 hours. As NeRF-- prioritizes learning camera parameters over speed, its slow training time aligns with its design. The authors of the NeRF-- paper noted that, in one of their experiments, NeRF-- took around 30 minutes longer to train compared to traditional NeRF due to the added complexity of using rays with learned camera parameters.<br />
Further experiments were conducted with images captured of the quad, this time from the 3rd floor. The final rendered image is as follows:
![Final 3RD FL Render](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/Images/3RDFLRender.png) <br />
The PSNR chart for the rendering of the quad using images captured from the 3rd floor is shown below:
![3RD FL PSNR](https://github.com/Tommy-Nguyen-cpu/Disaster-Management-NeRF/blob/main/Images/PSNR3RDFL.png) <br />
In contrast to the second-floor scene's PSNR score, the third-floor PSNR value appears to stabilize at a marginally lower level. Despite having a lower PSNR score compared to the second floor scene, the rendered image from the third floor seems clearer and contains fewer overall artifacts. <br />
While the final rendered image of the third-floor scene displays fewer artifacts compared to the second floor, its PSNR score surprisingly remains lower. This anomaly could arise from the second-floor rendered image being slightly less blurred, suggesting a marginally superior image quality despite the presence of additional artifacts. <br />
Possible causes for the lower PSNR score and render quality are varied: lighting discrepancies on the second and third floors, an insufficient number of images, suboptimal image positioning, image resizing issue, among others. <br />
Our findings suggest that NeRF--, while an intriguing alternative, currently faces limitations in terms of computational resources and training time. The model's 2-hour training duration for 6 images and 10,000 iterations is impractical for time-critical disaster management scenarios. Nevertheless, with further modifications and optimizations, NeRF-- holds potential for practical application in disaster management.

## Discussion
As explained in the "Result" section, both experiments concluded with the model producing a PSNR score that plateaued at approximately 22. Possible causes for this stagnation are varied: lighting discrepancies on the second and third floors, an insufficient number of images, suboptimal image positioning, among others. Hence, a more in-depth analysis is essential for a comprehensive understanding of the issue. <br />
Although the rendered images display noticeable levels of artifacts, it is apparent that NeRF-- shows potential in 3D model generation using only images; the rendered image not only captures smaller scene details like the background tree and the distant yellow chairs, albeit with slight obscurity, but also demonstrates an ability to discern contrasting colors in the backdrop, such as the yellow leaves on the tree and the varying shades in the grass. While the conducted experiments have highlighted the potential of NeRF-- in disaster management, future testing calls for experiments encompassing diverse disaster-affected scenes based on a given set of images in order to analyze NeRF-- performance on disaster-inflicted terrains. <br />
Despite the potential usage of NeRF-- in disaster management, a major drawback of the model is its extensive training time. NeRF--, due to its training in predicting camera parameters, volume density, and color, demands more training time than the traditional NeRF model. Consequently, NeRF-- exhibits notably slower performance compared to several other NeRF variants like FastNeRF and Instant-NGP. The inefficiency in its training time could be attributed to various factors. Firstly, its implementation in Python heavily relies on functionalities inherently slower compared to equivalent functionalities in programming languages such as C++ or Java. In turn, a C++ implementation of NeRF-- may produce significantly faster performance than the Python implementation. Furthermore, the additional thirty minutes required in training, compared to the conventional NeRF, can be attributed to NeRF-- constructing ray directions from learned camera parameters. While this additional time is inevitable, its reduction could be streamlined by implementing the model in a different programming language. Another contributing factor to the protracted training time in NeRF-- is its ray marching technique, known for its computational demands due to the necessity of radiance accumulation at every point along a ray. This becomes particularly resource-intensive in complex scenes. To address this challenge, altering the sampling approach, such as adopting NeRF's hierarchical sampling method described in "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis", could provide a potential solution. Moreover, expediting training time might entail leveraging hardware acceleration. Future endeavors could focus on incorporating these optimization strategies into NeRF--, paving the way for its enhanced practical application in disaster management.

## Summary
The project explores the potential utilization of NeRF-- in disaster management scenarios. Specifically, NeRF-- demonstrates promise in generating photorealistic models that could assist response teams in navigating through disaster-stricken terrains efficiently. However, NeRF-- currently grapples with three significant limitations: it undergoes slow training, operates solely on forward-facing scenes, and necessitates specific image formatting. The conducted experiments showcase these challenges, evident in the low PSNR score and extensive training duration. Further experimentation is vital to discern whether the low PSNR score and increased artifacts are due to input image quality or inherent limitations within the model itself. These existing constraints presently restrict its applicability, but with ongoing enhancements, NeRF-- holds potential to evolve into a valuable tool for generating realistic 3D models in disaster management scenarios.

## NeRF-- Setup
In order to get NeRF-- to work on your computer, you must create a virtual environment that has the required libraries. <br />
"python -m venv {Some-Environment-Name}"<br />
Once an environment has been created, download "torch" and "torchvision" following the steps outlined for your specific system on the following site: https://pytorch.org/get-started/locally/ <br />
Once "torch" and "torchvision" has been installed, pip install the libraries listed in "requirements.txt": <br />
"pip install -r requirements.txt" <br />
Now that the corresponding libraries have been created, you should now be able to run the jupyter notebook!
